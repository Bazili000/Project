import logging
import pandas as pd
import numpy as np
import nltk
import string
import matplotlib.pyplot as plt
import io

from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    ContextTypes, CallbackQueryHandler, filters
)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split

import plotly.express as px
import plotly.io as pio

nltk.download('stopwords')

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

TOKEN = '7169787095:AAHDGZWRncRFV7-ltAC-x0_qtTDEawNr2-c'

# --- –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---


def preprocess_text(text):
    stemmer = SnowballStemmer("english")
    stop_words = set(stopwords.words("english"))
    text = text.lower()
    text = ''.join([c for c in text if c not in string.punctuation])
    tokens = text.split()
    tokens = [stemmer.stem(
        word) for word in tokens if word not in stop_words]
    return ' '.join(tokens)


# –î–µ–º–æ –¥–∞–Ω–Ω—ã–µ
texts = [
    "Artificial intelligence and machine learning are transforming the world.",
    "The economy is showing signs of recovery after the pandemic.",
    "The new movie was a blockbuster hit and received positive reviews.",
    "Scientists have discovered a new species in the Amazon rainforest.",
    "Climate change is one of the biggest challenges facing humanity.",
    "Input the neural network to analyze the data system algorithm.",
    "Generate output layers with convolutional neural networks architecture.",
    "The transformer model utilizes attention mechanisms for processing.",
    "Compute the gradients and update the weights in the backpropagation.",
    "The AI is intelligent and can mimic human-like text generation."
]

labels = ['human', 'human', 'human', 'human', 'human',
          'ai', 'ai', 'ai', 'ai', 'ai']

data = pd.DataFrame({'text': texts, 'label': labels})
data['processed_text'] = data['text'].apply(preprocess_text)

X = data['processed_text']
y = data['label']

vectorizer = TfidfVectorizer()
X_vectors = vectorizer.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_vectors, y, test_size=0.2, random_state=42)

model = MultinomialNB()
model.fit(X_train, y_train)

accuracy = model.score(X_test, y_test)
print(f"–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {accuracy * 100:.2f}%")

# --- –ë–æ—Ç ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [
            InlineKeyboardButton('–ü–æ–º–æ—â—å', callback_data='help'),
            InlineKeyboardButton('–û –±–æ—Ç–µ', callback_data='about')
        ],
        [
            InlineKeyboardButton('–ü–æ–∫–∞–∑–∞—Ç—å 3D –≥—Ä–∞—Ñ–∏–∫', callback_data='show_3d_graph')
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–µ–º –Ω–∞–ø–∏—Å–∞–Ω —Ç–µ–∫—Å—Ç: —á–µ–ª–æ–≤–µ–∫–æ–º –∏–ª–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º.\n\n"
        "–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ, –∏ —è –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –µ–≥–æ.",
        reply_markup=reply_markup
    )


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.callback_query:
        await update.callback_query.answer()
        await update.callback_query.message.reply_text(
            "üìù *–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –±–æ—Ç–∞:*\n\n"
            "1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ.\n"
            "2. –Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –µ–≥–æ –∏ —Å–æ–æ–±—â—É, –∫–µ–º –æ–Ω –≤–µ—Ä–æ—è—Ç–Ω–µ–µ –≤—Å–µ–≥–æ –Ω–∞–ø–∏—Å–∞–Ω: —á–µ–ª–æ–≤–µ–∫–æ–º –∏–ª–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º.\n"
            "3. –í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å 3D –≥—Ä–∞—Ñ–∏–∫, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –∞–Ω–∞–ª–∏–∑–æ–º –¥–∞–Ω–Ω—ã—Ö.",
            parse_mode='Markdown'
        )
    else:
        await update.message.reply_text(
            "üìù *–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –±–æ—Ç–∞:*\n\n"
            "1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ.\n"
            "2. –Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –µ–≥–æ –∏ —Å–æ–æ–±—â—É, –∫–µ–º –æ–Ω –≤–µ—Ä–æ—è—Ç–Ω–µ–µ –≤—Å–µ–≥–æ –Ω–∞–ø–∏—Å–∞–Ω: —á–µ–ª–æ–≤–µ–∫–æ–º –∏–ª–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º.\n"
            "3. –í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å 3D –≥—Ä–∞—Ñ–∏–∫, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –∞–Ω–∞–ª–∏–∑–æ–º –¥–∞–Ω–Ω—ã—Ö.",
            parse_mode='Markdown'
        )


async def about_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.callback_query:
        await update.callback_query.answer()
        await update.callback_query.message.reply_text(
            "ü§ñ *–û –±–æ—Ç–µ:*\n\n"
            "–Ø –∏—Å–ø–æ–ª—å–∑—É—é –∞–ª–≥–æ—Ä–∏—Ç–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Ö –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—è.\n"
            "–°–æ–∑–¥–∞–Ω –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π NLP –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ Telegram Bot API.",
            parse_mode='Markdown'
        )
    else:
        await update.message.reply_text(
            "ü§ñ *–û –±–æ—Ç–µ:*\n\n"
            "–Ø –∏—Å–ø–æ–ª—å–∑—É—é –∞–ª–≥–æ—Ä–∏—Ç–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Ö –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—è.\n"
            "–°–æ–∑–¥–∞–Ω –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π NLP –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ Telegram Bot API.",
            parse_mode='Markdown'
        )


async def send_3d_graph(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.callback_query.answer()
    df = px.data.iris()
    fig = px.scatter_3d(df, x='sepal_length', y='sepal_width',
                        z='petal_length', color='species')
    fig.update_layout(title='3D Scatter Plot')

    graph_filename = '3d_graph.html'
    pio.write_html(fig, file=graph_filename, auto_open=False)

    with open(graph_filename, 'rb') as f:
        await update.callback_query.message.reply_document(document=f, filename=graph_filename)


async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    data = query.data

    if data == 'help':
        await help_command(update, context)
    elif data == 'about':
        await about_command(update, context)
    elif data == 'show_3d_graph':
        await send_3d_graph(update, context)
    else:
        await query.answer()


async def analyze_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text
    processed_text = preprocess_text(user_text)
    text_vector = vectorizer.transform([processed_text])

    prediction = model.predict(text_vector)[0]

    if prediction == 'human':
        response = "‚úçÔ∏è –≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç, –≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–∞–ø–∏—Å–∞–Ω *—á–µ–ª–æ–≤–µ–∫–æ–º*."
    else:
        response = "ü§ñ –≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç, –≤–µ—Ä–æ—è—Ç–Ω–æ, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω *–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º*."

    await update.message.reply_text(response, parse_mode='Markdown')

    user_data = context.user_data
    user_data['analysis'] = user_data.get('analysis', [])
    user_data['analysis'].append(prediction)


async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_data = context.user_data
    analysis = user_data.get('analysis', [])

    if not analysis:
        await update.message.reply_text("–í—ã –µ—â—ë –Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ —Ç–µ–∫—Å—Ç—ã.")
        return

    human_count = analysis.count('human')
    ai_count = analysis.count('ai')

    labels = ['–ß–µ–ª–æ–≤–µ–∫', '–ò–ò']
    counts = [human_count, ai_count]

    fig, ax = plt.subplots()
    ax.bar(labels, counts, color=['skyblue', 'salmon'])
    ax.set_title('–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–æ–≤')
    ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')

    buffer = io.BytesIO()
    plt.savefig(buffer, format='png')
    buffer.seek(0)
    plt.close(fig)

    await update.message.reply_photo(photo=buffer)

def main():
    application = ApplicationBuilder().token(TOKEN).build()

    application.add_handler(CommandHandler('start', start))
    application.add_handler(CommandHandler('help', help_command))
    application.add_handler(CommandHandler('about', about_command))
    application.add_handler(CommandHandler('stats', stats_command))
    application.add_handler(CallbackQueryHandler(button_handler))
    application.add_handler(MessageHandler(
        filters.TEXT & ~filters.COMMAND, analyze_text))

    application.run_polling()


if __name__ == '__main__':
    main()
